{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Azat Dovgeldiyev\n",
    "#import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. PCA for Reduced Dimensionality in Clustering\n",
    "#### a)\n",
    "Load in the image data matrix (with rows as images and columns as features). Also load in the numeric class labels from the segmentation class file. Using your favorite method (e.g., sklearn's min-max scaler), perform min-max normalization on the data matrix so that each feature is scaled to [0,1] range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>1.186342</td>\n",
       "      <td>12.925926</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>9.222222</td>\n",
       "      <td>18.666668</td>\n",
       "      <td>-6.111111</td>\n",
       "      <td>-11.111111</td>\n",
       "      <td>17.222221</td>\n",
       "      <td>18.666668</td>\n",
       "      <td>0.508139</td>\n",
       "      <td>1.910864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.720082</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>0.750309</td>\n",
       "      <td>13.740741</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>10.333334</td>\n",
       "      <td>19.222221</td>\n",
       "      <td>-6.222222</td>\n",
       "      <td>-10.222222</td>\n",
       "      <td>16.444445</td>\n",
       "      <td>19.222221</td>\n",
       "      <td>0.463329</td>\n",
       "      <td>1.941465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>225.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.388889</td>\n",
       "      <td>2.195113</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.520234</td>\n",
       "      <td>12.259259</td>\n",
       "      <td>10.333334</td>\n",
       "      <td>9.333334</td>\n",
       "      <td>17.111110</td>\n",
       "      <td>-5.777778</td>\n",
       "      <td>-8.777778</td>\n",
       "      <td>14.555555</td>\n",
       "      <td>17.111110</td>\n",
       "      <td>0.480149</td>\n",
       "      <td>1.987902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>1.254621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.894427</td>\n",
       "      <td>12.703704</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>18.111110</td>\n",
       "      <td>-5.111111</td>\n",
       "      <td>-11.111111</td>\n",
       "      <td>16.222221</td>\n",
       "      <td>18.111110</td>\n",
       "      <td>0.500966</td>\n",
       "      <td>1.875362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.691215</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.005540</td>\n",
       "      <td>15.592592</td>\n",
       "      <td>13.888889</td>\n",
       "      <td>11.777778</td>\n",
       "      <td>21.111110</td>\n",
       "      <td>-5.111111</td>\n",
       "      <td>-11.444445</td>\n",
       "      <td>16.555555</td>\n",
       "      <td>21.111110</td>\n",
       "      <td>0.442661</td>\n",
       "      <td>1.863654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1   2    3    4         5         6         7         8   \\\n",
       "0  110.0  189.0   9  0.0  0.0  1.000000  0.666667  1.222222  1.186342   \n",
       "1   86.0  187.0   9  0.0  0.0  1.111111  0.720082  1.444444  0.750309   \n",
       "2  225.0  244.0   9  0.0  0.0  3.388889  2.195113  3.000000  1.520234   \n",
       "3   47.0  232.0   9  0.0  0.0  1.277778  1.254621  1.000000  0.894427   \n",
       "4   97.0  186.0   9  0.0  0.0  1.166667  0.691215  1.166667  1.005540   \n",
       "\n",
       "          9          10         11         12        13         14         15  \\\n",
       "0  12.925926  10.888889   9.222222  18.666668 -6.111111 -11.111111  17.222221   \n",
       "1  13.740741  11.666667  10.333334  19.222221 -6.222222 -10.222222  16.444445   \n",
       "2  12.259259  10.333334   9.333334  17.111110 -5.777778  -8.777778  14.555555   \n",
       "3  12.703704  11.000000   9.000000  18.111110 -5.111111 -11.111111  16.222221   \n",
       "4  15.592592  13.888889  11.777778  21.111110 -5.111111 -11.444445  16.555555   \n",
       "\n",
       "          16        17        18  \n",
       "0  18.666668  0.508139  1.910864  \n",
       "1  19.222221  0.463329  1.941465  \n",
       "2  17.111110  0.480149  1.987902  \n",
       "3  18.111110  0.500966  1.875362  \n",
       "4  21.111110  0.442661  1.863654  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"segmentation_data/segmentation_data.txt\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = pd.read_csv(\"segmentation_data/segmentation_classes.txt\", header = None, sep='\\t')\n",
    "classes = classes.iloc[:,1]\n",
    "classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43083004, 0.74166667, 0.        , ..., 0.12371135, 0.50813884,\n",
       "        0.83184923],\n",
       "       [0.33596838, 0.73333333, 0.        , ..., 0.12739322, 0.46332908,\n",
       "        0.83698646],\n",
       "       [0.88537549, 0.97083333, 0.        , ..., 0.11340205, 0.48014903,\n",
       "        0.84478233],\n",
       "       ...,\n",
       "       [0.50197628, 0.625     , 0.        , ..., 0.07216495, 0.5409177 ,\n",
       "        0.17591546],\n",
       "       [0.58893281, 0.6125    , 0.        , ..., 0.08100147, 0.50308645,\n",
       "        0.18478933],\n",
       "       [0.48616601, 0.62916667, 0.        , ..., 0.09646539, 0.4799313 ,\n",
       "        0.17037463]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_norm = min_max_scaler.fit_transform(df)\n",
    "X_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)\n",
    "Using the Kmeans implementation in scikit-learn, perform clustering on the image data (use K = 7 in your clustering so that later we can compare the clusters to the 7 pre-assigned image classes). Print the cluster centroids (use some formatting so that they are visually understandable). To evaluate your clusters, first perform Silhouette analysis on the clusters (compute Silhouette values for all instances in the data, and then compute the overall mean Silhouette value; optionally, you can provide a visaulization of the Silhouettes). Next, compare your 7 clusters to the 7 pre-assigned classes by computing the Completeness and Homogeneity values of the generated clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=1000,\n",
       "       n_clusters=7, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, max_iter=1000, verbose=0)\n",
    "kmeans.fit(X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 5, 2, 5, 5, 5, 5, 2, 2, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5,\n",
       "       5, 5, 2, 5, 2, 5, 2, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 2, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 2, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 2, 5, 2, 5, 5, 5, 2, 2,\n",
       "       2, 5, 2, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 5, 5, 2, 5, 2, 2, 5, 0,\n",
       "       5, 2, 5, 2, 5, 2, 2, 2, 4, 2, 2, 5, 5, 2, 2, 2, 2, 5, 2, 5, 5, 2,\n",
       "       5, 5, 5, 2, 2, 2, 5, 4, 5, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 4, 2, 2,\n",
       "       2, 4, 2, 5, 2, 5, 5, 2, 2, 2, 5, 2, 4, 5, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 5, 5, 5, 2, 5, 5, 2, 5, 4, 2, 2, 5, 2, 2, 2, 5, 2, 4, 5, 2, 2,\n",
       "       2, 2, 5, 2, 4, 2, 2, 2, 2, 2, 5, 2, 4, 2, 5, 5, 2, 5, 2, 2, 5, 5,\n",
       "       5, 2, 2, 5, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 5, 2, 4, 5, 2, 5,\n",
       "       2, 2, 2, 5, 4, 5, 2, 4, 5, 5, 5, 5, 5, 2, 2, 2, 5, 2, 5, 2, 6, 4,\n",
       "       6, 4, 4, 6, 4, 0, 4, 6, 4, 4, 4, 6, 6, 6, 6, 4, 4, 6, 6, 4, 4, 6,\n",
       "       4, 4, 4, 4, 4, 6, 6, 4, 6, 4, 4, 6, 4, 6, 6, 6, 6, 4, 6, 4, 6, 2,\n",
       "       6, 6, 2, 6, 4, 4, 6, 6, 4, 2, 4, 6, 6, 6, 6, 6, 4, 6, 6, 6, 4, 6,\n",
       "       4, 6, 0, 4, 4, 6, 6, 4, 6, 4, 6, 4, 4, 6, 6, 6, 6, 6, 6, 6, 4, 4,\n",
       "       4, 4, 4, 6, 6, 6, 6, 4, 4, 6, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = kmeans.predict(X_norm)\n",
    "clusters[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(REGION-CENTROID-COL,)</th>\n",
       "      <th>(REGION-CENTROID-ROW,)</th>\n",
       "      <th>(REGION-PIXEL-COUNT,)</th>\n",
       "      <th>(SHORT-LINE-DENSITY-5,)</th>\n",
       "      <th>(SHORT-LINE-DENSITY-2,)</th>\n",
       "      <th>(VEDGE-MEAN,)</th>\n",
       "      <th>(VEDGE-SD,)</th>\n",
       "      <th>(HEDGE-MEAN,)</th>\n",
       "      <th>(HEDGE-SD,)</th>\n",
       "      <th>(INTENSITY-MEAN,)</th>\n",
       "      <th>(RAWRED-MEAN,)</th>\n",
       "      <th>(RAWBLUE-MEAN,)</th>\n",
       "      <th>(RAWGREEN-MEAN,)</th>\n",
       "      <th>(EXRED-MEAN,)</th>\n",
       "      <th>(EXBLUE-MEAN,)</th>\n",
       "      <th>(EXGREEN-MEAN,)</th>\n",
       "      <th>(VALUE-MEAN,)</th>\n",
       "      <th>(SATURATION-MEAN,)</th>\n",
       "      <th>(HUE-MEAN,)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   (REGION-CENTROID-COL,)  (REGION-CENTROID-ROW,)  (REGION-PIXEL-COUNT,)  \\\n",
       "0                    0.77                    0.43                   0.00   \n",
       "1                    0.54                    0.15                   0.00   \n",
       "2                    0.30                    0.53                   0.00   \n",
       "3                    0.51                    0.81                   0.00   \n",
       "4                    0.26                    0.39                   0.00   \n",
       "5                    0.75                    0.53                   0.00   \n",
       "6                    0.25                    0.46                   0.00   \n",
       "\n",
       "   (SHORT-LINE-DENSITY-5,)  (SHORT-LINE-DENSITY-2,)  (VEDGE-MEAN,)  \\\n",
       "0                     0.01                     0.02           0.04   \n",
       "1                     0.03                     0.00           0.03   \n",
       "2                     0.05                     0.05           0.10   \n",
       "3                     0.08                     0.01           0.05   \n",
       "4                     0.07                     0.02           0.08   \n",
       "5                     0.04                     0.04           0.11   \n",
       "6                     0.03                     0.01           0.04   \n",
       "\n",
       "   (VEDGE-SD,)  (HEDGE-MEAN,)  (HEDGE-SD,)  (INTENSITY-MEAN,)  (RAWRED-MEAN,)  \\\n",
       "0         0.00           0.02         0.00               0.04            0.04   \n",
       "1         0.00           0.03         0.00               0.82            0.78   \n",
       "2         0.01           0.08         0.01               0.40            0.37   \n",
       "3         0.00           0.05         0.00               0.11            0.09   \n",
       "4         0.00           0.06         0.00               0.15            0.14   \n",
       "5         0.02           0.11         0.02               0.30            0.28   \n",
       "6         0.00           0.03         0.00               0.03            0.02   \n",
       "\n",
       "   (RAWBLUE-MEAN,)  (RAWGREEN-MEAN,)  (EXRED-MEAN,)  (EXBLUE-MEAN,)  \\\n",
       "0             0.06              0.03           0.78            0.22   \n",
       "1             0.89              0.79           0.27            0.67   \n",
       "2             0.47              0.35           0.50            0.57   \n",
       "3             0.09              0.14           0.68            0.08   \n",
       "4             0.19              0.12           0.72            0.34   \n",
       "5             0.35              0.27           0.59            0.45   \n",
       "6             0.04              0.02           0.77            0.22   \n",
       "\n",
       "   (EXGREEN-MEAN,)  (VALUE-MEAN,)  (SATURATION-MEAN,)  (HUE-MEAN,)  \n",
       "0             0.49           0.06                0.54         0.24  \n",
       "1             0.29           0.89                0.21         0.13  \n",
       "2             0.21           0.47                0.30         0.16  \n",
       "3             0.82           0.13                0.41         0.89  \n",
       "4             0.36           0.19                0.41         0.20  \n",
       "5             0.31           0.35                0.30         0.16  \n",
       "6             0.51           0.04                0.80         0.18  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the cluster centroids (use some formatting so that they are visually understandable)\n",
    "names = pd.read_csv(\"segmentation_data/segmentation_names.txt\", header = None, sep='\\t')\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_, columns = names)\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57236961 0.5609926  0.46573747 0.49551578 0.57187855 0.56013527\n",
      " 0.54247867 0.41254281 0.51997981 0.46760414 0.48688779 0.49140278\n",
      " 0.58437635 0.56254708 0.3794524  0.5311416  0.54891047 0.4226305\n",
      " 0.4161636  0.40382238]\n"
     ]
    }
   ],
   "source": [
    "#compute Silhouette values for all instances in the data, and then compute the overall mean Silhouette value;\n",
    "from sklearn import metrics\n",
    "\n",
    "silhouettes = metrics.silhouette_samples(X_norm,clusters)\n",
    "print(silhouettes[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3320776409159453\n"
     ]
    }
   ],
   "source": [
    "print(silhouettes.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copied from class example (Clustering)\n",
    "import pylab as pl\n",
    "\n",
    "def plot_silhouettes(data, clusters, metric='euclidean'):\n",
    "    \n",
    "    from matplotlib import cm\n",
    "    from sklearn.metrics import silhouette_samples\n",
    "\n",
    "    cluster_labels = np.unique(clusters)\n",
    "    n_clusters = cluster_labels.shape[0]\n",
    "    silhouette_vals = metrics.silhouette_samples(data, clusters, metric='euclidean')\n",
    "    c_ax_lower, c_ax_upper = 0, 0\n",
    "    cticks = []\n",
    "    for i, k in enumerate(cluster_labels):\n",
    "        c_silhouette_vals = silhouette_vals[clusters == k]\n",
    "        c_silhouette_vals.sort()\n",
    "        c_ax_upper += len(c_silhouette_vals)\n",
    "        color = cm.jet(float(i) / n_clusters)\n",
    "        pl.barh(range(c_ax_lower, c_ax_upper), c_silhouette_vals, height=1.0, \n",
    "                      edgecolor='none', color=color)\n",
    "\n",
    "        cticks.append((c_ax_lower + c_ax_upper) / 2)\n",
    "        c_ax_lower += len(c_silhouette_vals)\n",
    "    \n",
    "    silhouette_avg = np.mean(silhouette_vals)\n",
    "    pl.axvline(silhouette_avg, color=\"red\", linestyle=\"--\") \n",
    "\n",
    "    pl.yticks(cticks, cluster_labels)\n",
    "    pl.ylabel('Cluster')\n",
    "    pl.xlabel('Silhouette coefficient')\n",
    "\n",
    "    pl.tight_layout()\n",
    "    #pl.savefig('images/11_04.png', dpi=300)\n",
    "    pl.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_silhouettes(X_norm, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Completeness score:  0.6132074717141492\n",
      "The Homogeneity score:  0.6115130439578844\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Next, compare your 7 clusters to the 7 pre-assigned classes by computing \n",
    "the Completeness and Homogeneity values of the generated clusters.\n",
    "'''\n",
    "from sklearn.metrics import completeness_score, homogeneity_score\n",
    "\n",
    "print('The Completeness score: ',completeness_score(classes, clusters))\n",
    "print('The Homogeneity score: ',homogeneity_score(classes, clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)\n",
    "Perform PCA on the normalized image data matrix. You may use the linear algebra package in Numpy or the Decomposition module in scikit-learn (the latter is much more efficient). Analyze the principal components to determine the number, r, of PCs needed to capture at least 95% of variance in the data. Provide a plot of PC variances. Then use these r components as features to transform the data into a reduced dimension space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.08  0.    0.   -0.   -0.   -0.    0.   -0.    0.    0.    0.    0.01  0.01 -0.01  0.    0.\n",
      "   0.01 -0.01  0.  ]\n",
      " [ 0.    0.06  0.    0.    0.    0.   -0.    0.   -0.   -0.03 -0.03 -0.03 -0.03  0.02 -0.02  0.02\n",
      "  -0.03  0.    0.04]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.  ]\n",
      " [-0.    0.    0.    0.02 -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.   -0.    0.   -0.    0.\n",
      "  -0.   -0.    0.  ]\n",
      " [-0.    0.    0.   -0.    0.01  0.    0.    0.    0.   -0.   -0.   -0.   -0.   -0.    0.   -0.\n",
      "  -0.    0.   -0.  ]\n",
      " [-0.    0.    0.   -0.    0.    0.01  0.    0.    0.   -0.   -0.    0.   -0.   -0.    0.   -0.\n",
      "   0.   -0.   -0.  ]\n",
      " [ 0.   -0.    0.   -0.    0.    0.    0.    0.    0.   -0.   -0.    0.    0.   -0.    0.    0.\n",
      "   0.    0.   -0.  ]\n",
      " [-0.    0.    0.   -0.    0.    0.    0.    0.01  0.    0.    0.    0.    0.   -0.    0.   -0.\n",
      "   0.   -0.   -0.  ]\n",
      " [ 0.   -0.    0.   -0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   -0.    0.   -0.\n",
      "   0.   -0.   -0.  ]\n",
      " [ 0.   -0.03  0.   -0.   -0.   -0.   -0.    0.    0.    0.07  0.07  0.08  0.07 -0.04  0.04 -0.03\n",
      "   0.08 -0.04 -0.02]\n",
      " [ 0.   -0.03  0.   -0.   -0.   -0.   -0.    0.    0.    0.07  0.07  0.07  0.06 -0.04  0.04 -0.03\n",
      "   0.07 -0.04 -0.02]\n",
      " [ 0.01 -0.03  0.   -0.   -0.    0.    0.    0.    0.    0.08  0.07  0.08  0.07 -0.05  0.05 -0.03\n",
      "   0.08 -0.04 -0.03]\n",
      " [ 0.01 -0.03  0.   -0.   -0.   -0.    0.    0.    0.    0.07  0.06  0.07  0.06 -0.04  0.04 -0.02\n",
      "   0.07 -0.04 -0.02]\n",
      " [-0.01  0.02  0.    0.   -0.   -0.   -0.   -0.   -0.   -0.04 -0.04 -0.05 -0.04  0.04 -0.03  0.02\n",
      "  -0.05  0.02  0.01]\n",
      " [ 0.   -0.02  0.   -0.    0.    0.    0.    0.    0.    0.04  0.04  0.05  0.04 -0.03  0.04 -0.03\n",
      "   0.05 -0.02 -0.03]\n",
      " [ 0.    0.02  0.    0.   -0.   -0.    0.   -0.   -0.   -0.03 -0.03 -0.03 -0.02  0.02 -0.03  0.04\n",
      "  -0.03  0.01  0.04]\n",
      " [ 0.01 -0.03  0.   -0.   -0.    0.    0.    0.    0.    0.08  0.07  0.08  0.07 -0.05  0.05 -0.03\n",
      "   0.08 -0.04 -0.03]\n",
      " [-0.01  0.    0.   -0.    0.   -0.    0.   -0.   -0.   -0.04 -0.04 -0.04 -0.04  0.02 -0.02  0.01\n",
      "  -0.04  0.05 -0.  ]\n",
      " [ 0.    0.04  0.    0.   -0.   -0.   -0.   -0.   -0.   -0.02 -0.02 -0.03 -0.02  0.01 -0.03  0.04\n",
      "  -0.03 -0.    0.07]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "meanVals = np.mean(X_norm, axis = 0)\n",
    "meanRemoved = X_norm - meanVals # remove mean\n",
    "covMat = np.cov(meanRemoved, rowvar=0)\n",
    "\n",
    "np.set_printoptions(precision=2, suppress = True, linewidth=100)\n",
    "print(covMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.linalg as la\n",
    "eigVals, eigVects = la.eig(np.mat(covMat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48 0.1  0.08 0.04 0.03 0.02 0.01 0.01 0.01 0.01 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n"
     ]
    }
   ],
   "source": [
    "print(eigVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03 -0.35  0.93  0.04  0.01 -0.03  0.01  0.03 -0.   -0.02 -0.01 -0.01  0.    0.    0.    0.\n",
      "  -0.    0.    0.  ]\n",
      " [-0.19 -0.38 -0.12 -0.66  0.47 -0.14 -0.24  0.22  0.06  0.07  0.06  0.04  0.01 -0.01 -0.    0.\n",
      "  -0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    1.  ]\n",
      " [-0.01 -0.03 -0.04 -0.03 -0.06 -0.6   0.72  0.32  0.06  0.08  0.01  0.01  0.   -0.   -0.    0.\n",
      "   0.   -0.    0.  ]\n",
      " [-0.    0.02  0.01 -0.1   0.09  0.44  0.28  0.32 -0.77  0.05  0.07  0.   -0.01  0.    0.   -0.\n",
      "  -0.   -0.    0.  ]\n",
      " [ 0.    0.02  0.01 -0.12  0.03  0.42  0.3   0.11  0.44 -0.34  0.55 -0.28  0.11 -0.01  0.    0.\n",
      "  -0.    0.    0.  ]\n",
      " [ 0.    0.01  0.01 -0.01  0.01  0.18  0.12  0.07  0.18 -0.14  0.05  0.77 -0.55  0.01 -0.   -0.\n",
      "  -0.   -0.    0.  ]\n",
      " [ 0.01  0.   -0.   -0.14  0.03  0.33  0.19  0.16  0.29 -0.02 -0.77 -0.29 -0.21 -0.01  0.   -0.\n",
      "   0.    0.    0.  ]\n",
      " [ 0.    0.    0.   -0.02  0.01  0.16  0.09  0.07  0.13 -0.05 -0.24  0.49  0.8   0.01  0.    0.\n",
      "   0.   -0.    0.  ]\n",
      " [ 0.38 -0.11 -0.06  0.09  0.05 -0.02 -0.08  0.16  0.01 -0.05  0.   -0.    0.   -0.21 -0.04  0.06\n",
      "   0.64 -0.63  0.  ]\n",
      " [ 0.36 -0.11 -0.07  0.09 -0.01 -0.04 -0.13  0.24  0.   -0.11 -0.   -0.01  0.   -0.21 -0.52  0.55\n",
      "  -0.5   0.02  0.  ]\n",
      " [ 0.41 -0.07 -0.04  0.03  0.08 -0.03 -0.04  0.07 -0.01 -0.06 -0.01  0.    0.   -0.22  0.81  0.1\n",
      "  -0.33  0.17  0.  ]\n",
      " [ 0.36 -0.16 -0.08  0.14  0.06  0.01 -0.08  0.18  0.04  0.02  0.02 -0.    0.   -0.21 -0.19 -0.73\n",
      "   0.18  0.45  0.  ]\n",
      " [-0.24  0.06  0.    0.01 -0.39 -0.13 -0.31  0.5  -0.05 -0.42 -0.04 -0.03  0.    0.08  0.11 -0.25\n",
      "  -0.17 -0.26  0.  ]\n",
      " [ 0.26  0.18  0.08 -0.27  0.18 -0.04  0.18 -0.4  -0.08 -0.08 -0.04  0.02 -0.   -0.08 -0.11 -0.3\n",
      "  -0.32 -0.45  0.  ]\n",
      " [-0.18 -0.34 -0.13  0.43  0.11  0.2   0.03  0.14  0.17  0.55  0.1  -0.   -0.    0.05  0.06 -0.07\n",
      "  -0.26 -0.32  0.  ]\n",
      " [ 0.41 -0.1  -0.06  0.04  0.1  -0.02 -0.03  0.06 -0.   -0.07 -0.01 -0.02 -0.    0.89  0.   -0.\n",
      "  -0.    0.    0.  ]\n",
      " [-0.2   0.31  0.08  0.42  0.74 -0.12 -0.03  0.13 -0.01 -0.3  -0.06 -0.03 -0.   -0.01 -0.    0.\n",
      "  -0.   -0.    0.  ]\n",
      " [-0.17 -0.64 -0.24  0.2  -0.01 -0.02  0.18 -0.35 -0.18 -0.5  -0.12 -0.02 -0.   -0.04 -0.    0.\n",
      "  -0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(eigVects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48 0.1  0.08 0.04 0.03 0.02 0.01 0.01 0.01 0.01 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      "[60.71 13.2  10.12  4.54  3.55  1.99  1.89  1.62  1.07  0.71  0.39  0.16  0.05  0.    0.    0.\n",
      "  0.    0.    0.  ]\n"
     ]
    }
   ],
   "source": [
    "eigValInd = np.argsort(eigVals) # sort, sort goes smallest to largest\n",
    "eigValInd = eigValInd[::-1] #reverse\n",
    "sortedEigVals = eigVals[eigValInd]\n",
    "print(sortedEigVals)\n",
    "total = sum(sortedEigVals)\n",
    "varPercentage = sortedEigVals / total*100\n",
    "print(varPercentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 PC: 0.6071\n",
      "2 PC: 0.7391\n",
      "3 PC: 0.8403\n",
      "4 PC: 0.8858\n",
      "5 PC: 0.9213\n",
      "6 PC: 0.9411\n",
      "7 PC: 0.9601\n"
     ]
    }
   ],
   "source": [
    "var = 0\n",
    "for i in range(10):\n",
    "    var += varPercentage[i]/100\n",
    "    print(\"{} PC: {}\".format(i+1, round(var,4)))\n",
    "    if var >= 0.95:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(range(1, 11), varPercentage[:10], marker='^')\n",
    "plt.xlabel('Principal Component Number')\n",
    "plt.ylabel('Percentage of Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.69 -0.53 -0.25 ...  0.08  0.05 -0.05]\n",
      " [-0.67 -0.51 -0.34 ...  0.04  0.06 -0.04]\n",
      " [-0.71 -0.77  0.16 ...  0.17  0.04 -0.06]\n",
      " ...\n",
      " [-0.51  0.13  0.08 ...  0.03 -0.03 -0.11]\n",
      " [-0.48  0.09  0.16 ... -0.   -0.   -0.09]\n",
      " [-0.44  0.11  0.05 ... -0.02 -0.21  0.15]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Analyze the principal components to determine the number, \n",
    "r, of PCs needed to capture at least 95% of variance in the data. \n",
    "'''\n",
    "topNfeat = 7\n",
    "topEigValInd = eigValInd[:topNfeat]\n",
    "reducedEigVects = eigVects[:, topEigValInd]\n",
    "reducedDT = np.dot(meanRemoved, reducedEigVects)\n",
    "print(reducedDT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d)\n",
    "Perform Kmeans again, but this time on the lower dimensional transformed data. Then compare Silhouette values as well as completeness and Homogeneity values of the new clusters. Compare these results with those obtained on the full data in part b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=1000,\n",
       "       n_clusters=7, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=7, max_iter=1000, verbose=0)\n",
    "kmeans.fit(reducedDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 6, 2, 2, 2, 2, 6, 6, 2, 2, 2, 2, 2, 2,\n",
       "       2, 6, 2, 2, 2, 2, 6, 2, 6, 2, 6, 2, 2, 2, 2, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2,\n",
       "       6, 2, 6, 2, 2, 2, 6, 6, 6, 2, 6, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 2, 2, 6, 2, 6, 6, 2, 4, 2, 6, 2, 6, 2, 6,\n",
       "       6, 6, 5, 6, 6, 2, 2, 6, 6, 6, 6, 2, 6, 2, 2, 6, 2, 2, 2, 6, 6, 6, 2, 5, 2, 6, 6, 6, 6, 6, 2,\n",
       "       2, 2, 2, 2, 5, 6, 6, 6, 5, 6, 2, 6, 2, 2, 6, 6, 6, 2, 6, 5, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2,\n",
       "       2, 2, 6, 2, 2, 6, 2, 5, 6, 6, 2, 6, 6, 6, 2, 6, 5, 2, 6, 6, 6, 6, 2, 6, 5, 6, 6, 6, 6, 6, 2,\n",
       "       6, 5, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 2, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 2, 6, 2, 6, 5, 2,\n",
       "       6, 2, 6, 6, 6, 2, 5, 2, 6, 5, 2, 2, 2, 2, 2, 6, 6, 6, 2, 6, 2, 6, 1, 5, 1, 5, 5, 1, 5, 4, 5,\n",
       "       1, 5, 5, 5, 1, 1, 1, 1, 5, 5, 1, 1, 5, 5, 1, 5, 5, 5, 5, 5, 1, 1, 5, 1, 5, 5, 1, 5, 1, 1, 1,\n",
       "       1, 5, 1, 5, 1, 6, 1, 1, 6, 1, 5, 5, 1, 1, 5, 6, 5, 1, 1, 1, 1, 1, 5, 1, 1, 1, 5, 1, 5, 1, 4,\n",
       "       5, 5, 1, 1, 5, 1, 5, 1, 5, 5, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 1, 1, 1, 1, 1, 5, 5, 1, 0, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = kmeans.predict(reducedDT)\n",
    "clusters[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.41</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.60</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.51</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6\n",
       "0  1.41 -0.09 -0.04  0.17  0.03 -0.01 -0.02\n",
       "1 -0.60  0.36 -0.11  0.13  0.13 -0.02 -0.04\n",
       "2  0.18 -0.04  0.27 -0.18 -0.03  0.02  0.00\n",
       "3 -0.62 -0.64 -0.20  0.09  0.07  0.01  0.04\n",
       "4 -0.51  0.06  0.34  0.07 -0.08  0.01 -0.03\n",
       "5 -0.21  0.25 -0.15 -0.06 -0.13 -0.01  0.03\n",
       "6  0.44  0.10 -0.16 -0.23  0.05 -0.01  0.02"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_)\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3598202981349143\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "compare Silhouette values as well as completeness and \n",
    "Homogeneity values of the new clusters. \n",
    "Compare these results with those obtained on the full data in part b.\n",
    "'''\n",
    "\n",
    "silhouettes = metrics.silhouette_samples(reducedDT,clusters)\n",
    "print(silhouettes.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_silhouettes(reducedDT,clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness score:  0.6107955063694607\n",
      "Homogeneity score:  0.609136404973329\n"
     ]
    }
   ],
   "source": [
    "print(\"Completeness score: \", completeness_score(classes, clusters))\n",
    "print(\"Homogeneity score: \", homogeneity_score(classes, clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a small difference between scores, however mean slihouettes with reduced dimensions are higher than original, and one possible reason might be data is not overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Item-Based Joke Recommendation\n",
    "#### a)\n",
    "Load in the joke ratings data and the joke text data into appropriate data structures. Use the \"recommend\" function to provide top 5 joke recommendations for at least 2 users. Use both standard item-based collaborative filtering (based on the rating prediction function \"standEst\") and the SVD-based version of the item-based CF (using \"svdEst\" as the prediction engine) to generate these recommendations for the two users and note the differences. You should show the text of the recommended jokes as well as the predicted ratings for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.18</td>\n",
       "      <td>19.79</td>\n",
       "      <td>1.34</td>\n",
       "      <td>2.84</td>\n",
       "      <td>3.48</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.15</td>\n",
       "      <td>15.17</td>\n",
       "      <td>2.02</td>\n",
       "      <td>6.24</td>\n",
       "      <td>...</td>\n",
       "      <td>13.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.08</td>\n",
       "      <td>10.71</td>\n",
       "      <td>17.36</td>\n",
       "      <td>15.37</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.34</td>\n",
       "      <td>10.27</td>\n",
       "      <td>5.66</td>\n",
       "      <td>19.88</td>\n",
       "      <td>20.22</td>\n",
       "      <td>...</td>\n",
       "      <td>13.82</td>\n",
       "      <td>6.05</td>\n",
       "      <td>10.71</td>\n",
       "      <td>18.86</td>\n",
       "      <td>10.81</td>\n",
       "      <td>8.86</td>\n",
       "      <td>14.06</td>\n",
       "      <td>11.34</td>\n",
       "      <td>6.68</td>\n",
       "      <td>12.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.03</td>\n",
       "      <td>20.27</td>\n",
       "      <td>20.03</td>\n",
       "      <td>20.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>19.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.80</td>\n",
       "      <td>19.16</td>\n",
       "      <td>8.18</td>\n",
       "      <td>17.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.84</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.50</td>\n",
       "      <td>15.61</td>\n",
       "      <td>6.83</td>\n",
       "      <td>5.61</td>\n",
       "      <td>12.36</td>\n",
       "      <td>12.60</td>\n",
       "      <td>18.04</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.56</td>\n",
       "      <td>16.73</td>\n",
       "      <td>...</td>\n",
       "      <td>16.19</td>\n",
       "      <td>16.58</td>\n",
       "      <td>15.27</td>\n",
       "      <td>16.19</td>\n",
       "      <td>16.73</td>\n",
       "      <td>12.55</td>\n",
       "      <td>14.11</td>\n",
       "      <td>17.55</td>\n",
       "      <td>12.80</td>\n",
       "      <td>12.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3     4     5     6     7     8     9   ...    90  \\\n",
       "0  3.18 19.79  1.34  2.84  3.48  2.50  1.15 15.17  2.02  6.24  ... 13.82   \n",
       "1 15.08 10.71 17.36 15.37  8.62  1.34 10.27  5.66 19.88 20.22  ... 13.82   \n",
       "2  0.00  0.00  0.00  0.00 20.03 20.27 20.03 20.27  0.00  0.00  ...  0.00   \n",
       "3  0.00 19.35  0.00  0.00 12.80 19.16  8.18 17.21  0.00 12.84  ...  0.00   \n",
       "4 19.50 15.61  6.83  5.61 12.36 12.60 18.04 15.61 10.56 16.73  ... 16.19   \n",
       "\n",
       "     91    92    93    94    95    96    97    98    99  \n",
       "0  0.00  0.00  0.00  0.00  0.00  5.37  0.00  0.00  0.00  \n",
       "1  6.05 10.71 18.86 10.81  8.86 14.06 11.34  6.68 12.07  \n",
       "2  0.00  0.00 20.08  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "3  0.00  0.00 11.53  0.00  0.00  0.00  0.00  0.00  0.00  \n",
       "4 16.58 15.27 16.19 16.73 12.55 14.11 17.55 12.80 12.60  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"jokes/modified_jester_data.csv\", header = None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A man visits the doctor. The doctor says \"I ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>This couple had an excellent relationship goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Q. What's 200 feet long and has 4 teeth? A. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Q. What's the difference between a man and a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Q. What's O. J. Simpson's Internet address? A....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1\n",
       "0  0  A man visits the doctor. The doctor says \"I ha...\n",
       "1  1  This couple had an excellent relationship goin...\n",
       "2  2  Q. What's 200 feet long and has 4 teeth? A. Th...\n",
       "3  3  Q. What's the difference between a man and a t...\n",
       "4  4  Q. What's O. J. Simpson's Internet address? A...."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jokes = pd.read_csv(\"jokes/jokes.csv\", header=None)\n",
    "jokes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidSim(inA, inB):\n",
    "    return 1.0/(1.0 + la.norm(inA-inB))\n",
    "\n",
    "def pearsonSim(inA, inB):\n",
    "    if len(inA) < 3:\n",
    "        return 1.0\n",
    "    return 0.5 + 0.5*np.corrcoef(inA,inB, rowvar=0)[0][1]\n",
    "\n",
    "def cosineSim(inA,inB):\n",
    "    num = float(inA.T*inB)\n",
    "    denom = la.norm(inA) * la.norm(inB)\n",
    "    return 0.5 * 0.5 *(num/denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standEst(dataMat, user, simMeas, item):\n",
    "    n = np.shape(dataMat)[1]\n",
    "    simTotal = 0.0; ratSimTotal = 0.0\n",
    "    for j in range(n):\n",
    "        userRating = dataMat[user,j]\n",
    "        if userRating == 0: \n",
    "            continue\n",
    "        overLap = np.nonzero(np.logical_and(dataMat[:,item]>0, dataMat[:,j]>0))[0]\n",
    "        if len(overLap) == 0: \n",
    "            similarity = 0\n",
    "        else: \n",
    "            similarity = simMeas(dataMat[overLap,item], dataMat[overLap,j])\n",
    "        #print('the %d and %d similarity is: %f' % (item, j, similarity))\n",
    "        simTotal += similarity\n",
    "        ratSimTotal += similarity * userRating\n",
    "    if simTotal == 0: return 0\n",
    "    else: return ratSimTotal/simTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svdEst(dataMat, user, simMeas, item):\n",
    "    n = np.shape(dataMat)[1]\n",
    "    simTotal = 0.0; ratSimTotal = 0.0\n",
    "    data = np.mat(dataMat)\n",
    "    U,Sigma,VT = la.svd(data)\n",
    "    Sig4 = np.mat(np.eye(4)*Sigma[:4]) #arrange Sig4 into a diagonal matrix\n",
    "    xformedItems = data.T * U[:,:4] * Sig4.I  #create transformed items\n",
    "    for j in range(n):\n",
    "        userRating = data[user,j]\n",
    "        if userRating == 0 or j==item: continue\n",
    "        similarity = simMeas(xformedItems[item,:].T, xformedItems[j,:].T)\n",
    "        #print('the %d and %d similarity is: %f' % (item, j, similarity))\n",
    "        simTotal += similarity\n",
    "        ratSimTotal += similarity * userRating\n",
    "    if simTotal == 0: return 0\n",
    "    else: return ratSimTotal/simTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(dataMat, user, N=3, simMeas=cosineSim, estMethod=standEst):\n",
    "    unratedItems = np.nonzero(dataMat[user,:].A==0)[1] #find unrated items \n",
    "    if len(unratedItems) == 0: return 'you rated everything'\n",
    "    itemScores = []\n",
    "    for item in unratedItems:\n",
    "        estimatedScore = estMethod(dataMat, user, simMeas, item)\n",
    "        itemScores.append((item, estimatedScore))\n",
    "    return sorted(itemScores, key=lambda jj: jj[1], reverse=True)[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix= np.mat(df)\n",
    "user1 = 22\n",
    "recommend_standEst1 = recommend(df_matrix, user1, N=5, simMeas=cosineSim, estMethod=standEst)\n",
    "recommend_svdEst1 = recommend(df_matrix, user1, N=5, simMeas=cosineSim, estMethod=svdEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2 = 28\n",
    "recommend_standEst2 = recommend(df_matrix, user2, N=5, simMeas=cosineSim, estMethod=standEst)\n",
    "recommend_svdEst2 = recommend(df_matrix, user2, N=5, simMeas=cosineSim, estMethod=svdEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended jokes for user 1 with standEst:\n",
      "\n",
      "Ranking\tJoke No\t  Predicted rating\n",
      "\n",
      "1\t  88\t\t13.723945106997949\n",
      "A radio conversation of a US naval ship with Canadian authorities ... Americans: Please divert your course 15 degrees to the North to avoid a collision.Canadians: Recommend you divert YOUR course 15 degrees to the South to avoid a collision.Americans: This is the Captain of a US Navy ship.  I say again divert YOUR course.Canadians: No.  I say again you divert YOUR course.Americans: This is the aircraft carrier USS LINCOLN the second largest ship in the United States' Atlantic Fleet. We are accompanied by three destroyers three cruisers and numerous support vessels. I demand that you change your course 15 degrees north that's ONE FIVE DEGREES NORTH or counter-measures will be undertaken to ensure the safety of this ship.Canadians: This is a lighthouse.  Your call.\n",
      "\n",
      "2\t  97\t\t13.71399971741189\n",
      "Age and Womanhood1. Between the ages of 13 and 18 ... She is like Africa virgin and unexplored. 2. Between the ages of 19 and 35 ... She is like Asia hot and exotic. 3. Between the ages of 36 and 45 ... She is like America fully explored breathtakingly beautiful and free with her resources.4. Between the ages of 46 and 56 ...She is like Europe exhausted but still has points of interest. 5. After 56 she is like Australia ...Everybody knows it's down there but who gives a damn?\n",
      "\n",
      "3\t  71\t\t13.713536444834086\n",
      "On the first day of college the Dean addressed the students pointing out some of the rules:\"The female dormitory will be out-of-bounds for all male students and the male dormitory to the female students. Anybody caught breaking this rule will be fined $20 the first time.\" He continued \"Anybody caught breaking this rule the second time will be fined $60. Being caught a third time will cost you a fine of $180. Are there any questions ?\"At this point a male student in the crowd inquired:\"How much for a season pass ?\"\n",
      "\n",
      "4\t  99\t\t13.712396449308478\n",
      "Q: What's the difference between greeting a Queen and greeting thePresident of the United  States?A: You only have to get on one knee to greet the queen.\n",
      "\n",
      "5\t  70\t\t13.711675331095016\n",
      "At a recent Sacramento PC Users Group meeting a company was demonstrating its latest speech-recognition software.   A representative from the company was just about ready to start the demonstration and asked everyone in the room to quiet down.Just then someone in the back of the room yelled\"Format C: Return.\"Someone else chimed in:\"Yes Return\"Unfortunately the software worked.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Recommended jokes for user 1 with standEst:\\n\")\n",
    "print(\"Ranking\\tJoke No\\t  Predicted rating\\n\")\n",
    "for i in range(len(recommend_standEst1)):\n",
    "    print(\"{}\\t  {}\\t\\t{}\\n{}\\n\".format(i+1, recommend_standEst1[i][0],recommend_standEst1[i][1],\n",
    "                                      jokes.iloc[recommend_standEst1[i][0]][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended jokes for user 1 with svdEst:\n",
      "\n",
      "Ranking\tJoke No\t  Predicted rating\n",
      "\n",
      "1\t  98\t\t9.963702586498707\n",
      "A bus station is where a bus stops.A train station is where a train stops.On my desk I have a work station...\n",
      "\n",
      "2\t  96\t\t9.421607023153587\n",
      "A teacher is explaining to her class how different languages use negatives differently.  She says \"In all languages a positive followed by a negative or a negative followed by a positive makes a negative.  In some languages two negatives together make a positive while in others they make a negative.  But in no language do two positives make a negative.\"  One of the students puts up his hand and says \"Yeah right.\"\n",
      "\n",
      "3\t  97\t\t9.194928705654108\n",
      "Age and Womanhood1. Between the ages of 13 and 18 ... She is like Africa virgin and unexplored. 2. Between the ages of 19 and 35 ... She is like Asia hot and exotic. 3. Between the ages of 36 and 45 ... She is like America fully explored breathtakingly beautiful and free with her resources.4. Between the ages of 46 and 56 ...She is like Europe exhausted but still has points of interest. 5. After 56 she is like Australia ...Everybody knows it's down there but who gives a damn?\n",
      "\n",
      "4\t  92\t\t8.680631353691869\n",
      "Reaching the end of a job interview the human resources person asked a young engineer fresh out of Stanford\"And what starting salary were you looking for?\"The engineer said \"In the neighborhood of $125000 a year depending on the benefits package.\"The interviewer said \"Well what would you say to a package of 5-weeks vacation 14 paid holidays full medical and dental company matching retirement fund to 50% of salary and a company car leased every 2 years - say a red Corvette?\"The Engineer sat up straight and said \"Wow! Are you kidding?\"And the interviewer replied \"Yeah but you started it.\"\n",
      "\n",
      "5\t  94\t\t8.606309668652706\n",
      "Just a thought ..Before criticizing someone walk a mile in their shoes.  Then when you do criticize them you will be a mile away and have their shoes !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Recommended jokes for user 1 with svdEst:\\n\")\n",
    "print(\"Ranking\\tJoke No\\t  Predicted rating\\n\")\n",
    "for i in range(len(recommend_svdEst1)):\n",
    "    print(\"{}\\t  {}\\t\\t{}\\n{}\\n\".format(i+1, recommend_svdEst1[i][0],recommend_svdEst1[i][1],\n",
    "                                      jokes.iloc[recommend_svdEst1[i][0]][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended jokes for user 2 with standEst:\n",
      "\n",
      "Ranking\tJoke No\t  Predicted rating\n",
      "\n",
      "1\t  88\t\t13.446042696171508\n",
      "A radio conversation of a US naval ship with Canadian authorities ... Americans: Please divert your course 15 degrees to the North to avoid a collision.Canadians: Recommend you divert YOUR course 15 degrees to the South to avoid a collision.Americans: This is the Captain of a US Navy ship.  I say again divert YOUR course.Canadians: No.  I say again you divert YOUR course.Americans: This is the aircraft carrier USS LINCOLN the second largest ship in the United States' Atlantic Fleet. We are accompanied by three destroyers three cruisers and numerous support vessels. I demand that you change your course 15 degrees north that's ONE FIVE DEGREES NORTH or counter-measures will be undertaken to ensure the safety of this ship.Canadians: This is a lighthouse.  Your call.\n",
      "\n",
      "2\t  83\t\t13.443908142499966\n",
      "Q: What is the difference between Mechanical Engineers and Civil Engineers? A: Mechanical Engineers build weapons Civil Engineers build targets.\n",
      "\n",
      "3\t  96\t\t13.443200281598052\n",
      "A teacher is explaining to her class how different languages use negatives differently.  She says \"In all languages a positive followed by a negative or a negative followed by a positive makes a negative.  In some languages two negatives together make a positive while in others they make a negative.  But in no language do two positives make a negative.\"  One of the students puts up his hand and says \"Yeah right.\"\n",
      "\n",
      "4\t  0\t\t13.43814549128179\n",
      "A man visits the doctor. The doctor says \"I have bad news for you.You have cancer and Alzheimer's disease\". The man replies \"Well thank God I don't have cancer!\"\n",
      "\n",
      "5\t  70\t\t13.4341374282765\n",
      "At a recent Sacramento PC Users Group meeting a company was demonstrating its latest speech-recognition software.   A representative from the company was just about ready to start the demonstration and asked everyone in the room to quiet down.Just then someone in the back of the room yelled\"Format C: Return.\"Someone else chimed in:\"Yes Return\"Unfortunately the software worked.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Recommended jokes for user 2 with standEst:\\n\")\n",
    "print(\"Ranking\\tJoke No\\t  Predicted rating\\n\")\n",
    "for i in range(len(recommend_standEst2)):\n",
    "    print(\"{}\\t  {}\\t\\t{}\\n{}\\n\".format(i+1, recommend_standEst2[i][0],recommend_standEst2[i][1],\n",
    "                                      jokes.iloc[recommend_standEst2[i][0]][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended jokes for user 2 with svdEst:\n",
      "\n",
      "Ranking\tJoke No\t  Predicted rating\n",
      "\n",
      "1\t  93\t\t19.419519166102475\n",
      "Two atoms are walking down the street when one atom says to the other \"Oh my! I've lost an electron!\"The second atom says\"Are you sure\"The first replies \"I'm positive!\"\n",
      "\n",
      "2\t  0\t\t17.095672982073086\n",
      "A man visits the doctor. The doctor says \"I have bad news for you.You have cancer and Alzheimer's disease\". The man replies \"Well thank God I don't have cancer!\"\n",
      "\n",
      "3\t  87\t\t16.742958970742617\n",
      "A Czechoslovakian man felt his eyesight was growing steadily worse and felt it was time to go see an optometrist. The doctor started with some simple testing and showed him a standard eye chart with letters of diminishing size: CRKBNWXSKZY. . . \"Can you read this?\" the doctor asked. \"Read it?\" the Czech answered. \"Doc I know him!\"\n",
      "\n",
      "4\t  1\t\t15.335639358993708\n",
      "This couple had an excellent relationship going until one day he came home from work to find his girlfriend packing. He asked her why she was leaving him and she told him that she had heard awful things about him. \"What could they possibly have said to make you move out?\" \"They told me that you were a pedophile.\" He replied \"That's an awfully big word for a ten year old.\" \n",
      "\n",
      "5\t  96\t\t14.555201643849147\n",
      "A teacher is explaining to her class how different languages use negatives differently.  She says \"In all languages a positive followed by a negative or a negative followed by a positive makes a negative.  In some languages two negatives together make a positive while in others they make a negative.  But in no language do two positives make a negative.\"  One of the students puts up his hand and says \"Yeah right.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Recommended jokes for user 2 with svdEst:\\n\")\n",
    "print(\"Ranking\\tJoke No\\t  Predicted rating\\n\")\n",
    "for i in range(len(recommend_svdEst2)):\n",
    "    print(\"{}\\t  {}\\t\\t{}\\n{}\\n\".format(i+1, recommend_svdEst2[i][0],recommend_svdEst2[i][1],\n",
    "                                      jokes.iloc[recommend_svdEst2[i][0]][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall svd estimation for user 2 predicted higher scores, and standEst for user 1. Maybe predicted scores will change if we work around numbers around users. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)\n",
    "Complete the definition for the function \"test\". This function iterates over all users and for each performs evaluation (by calling the provided \"cross_validate_user\" function), and returns the error information necessary to compute Mean Absolute Error (MAE). Use this function to perform evaluation (with 20% test-ratio for each user) comparing MAE results using the rating prediction function \"standEst\" with results using the \"svdEst\" prediction function. [Note: See comments provided in the module for hints on accomplishing these tasks.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'jokes/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'itemBasedRec' from 'jokes\\\\itemBasedRec.py'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import itemBasedRec as ibr\n",
    "reload(ibr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataMat, test_ratio, estMethod, simMeas=pearsonSim):\n",
    "    t_error = 0\n",
    "    t_count = 0\n",
    "    for i in range(len(dataMat)):\n",
    "        error, count = ibr.cross_validate_user(dataMat, i, test_ratio, eval(estMethod), simMeas)\n",
    "        t_error+=error\n",
    "        t_count+=count\n",
    "    MAE = t_error/t_count\n",
    "    \n",
    "    return MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.708023520032522\n"
     ]
    }
   ],
   "source": [
    "standEst_MAE = test(df, 0.2, \"standEst\")\n",
    "print(standEst_MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.631338000855049\n"
     ]
    }
   ],
   "source": [
    "svdEst_MAE = test(df, 0.2, \"svdEst\")\n",
    "print(svdEst_MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_most_similar_jokes(dataMat, jokes, queryJoke, k, metric=pearsonSim):\n",
    "    jokes_transpose = dataMat.T\n",
    "    sims =[]\n",
    "    for i in range(len(jokes_transpose)):\n",
    "        if (i==queryJoke):\n",
    "            continue;\n",
    "        sim = metric(jokes_transpose[queryJoke], jokes_transpose[i])\n",
    "        sims.append((sim,i))\n",
    "    sims.sort(reverse = True)\n",
    "    print(\"top {} most similar jokes to {}:\\n\\n{}\".format(k,queryJoke,jokes.iloc[queryJoke][1]))\n",
    "    for i in range(k):\n",
    "        joke=sims[i]\n",
    "        print(\"\\nJoke {}, similarity {:0.6f}:\".format(i+1,joke[0]))\n",
    "        print(jokes.iloc[joke[1]][1])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 5 most similar jokes to 0:\n",
      "\n",
      "A man visits the doctor. The doctor says \"I have bad news for you.You have cancer and Alzheimer's disease\". The man replies \"Well thank God I don't have cancer!\"\n",
      "\n",
      "Joke 1, similarity 0.815454:\n",
      "Q. What's the difference between a man and a toilet? A. A toilet doesn't follow you around after you use it.\n",
      "\n",
      "Joke 2, similarity 0.814750:\n",
      "Q: What do Monica Lewinsky and Bob Dole have in common?A: They were both upset when Bill finished first.\n",
      "\n",
      "Joke 3, similarity 0.802881:\n",
      "Q: How do you keep a computer programmer in the shower all day long?A: Give them a shampoo with a label that says\"rinse lather repeat\".\n",
      "\n",
      "Joke 4, similarity 0.801244:\n",
      "A woman has twins and gives them up for adoption.  One of them goes to a family in Egypt and is named \"Amal.\"  The other goes to a  family in Spain; they name him \"Juan.\"  Years later Juan sends a picture of himself to his mom.  Upon receiving the picture she tells her husband that she wishes she also had a picture of Amal.  Her husband responds \"But they are twins-if you've seen Juan you've seen   Amal.\n",
      "\n",
      "Joke 5, similarity 0.798864:\n",
      "What's the difference between a MacIntosh and anEtch-A-Sketch? You don't have to shake the Mac to clear the screen. \n"
     ]
    }
   ],
   "source": [
    "print_most_similar_jokes(df,jokes,0,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d)\n",
    "[Extra Credit]: Develop your own item-based collaborative filtering recommender that uses a model-based approach (separating the training and the prediction tasks). In the training component, item-item similarities for all pairs of items are computed and stored in an appropriate data structure. Your training function should be able to use different similarity functions (passed as a parameter) including Cosine Similarity or Pearson Correlation. The prediction (or estimation) function should take as parameters a target user, an item, a value of k, and the similarities data structure and return the predicted rating on the target item for the target user. The predicted rating should be based on the weighted average of the target user's ratings on k most similar items to the target item. You should test the prediction accuracy of your estimation function (using a cross-validation similar to part b, above) and provide a plot of cross-validation accuracies across a range of values of k. Using the best value of k, demonstrate the functionality of your recommender by generating recommendations for several anecdotal users (similar to part a, above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_t = df.T\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_t, jokes, test_size=0.2, random_state = 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_items(data,metric=pearsonSim):\n",
    "    sims = []\n",
    "    for i in range(len(data)):\n",
    "        for j in range(i, len(data)):\n",
    "            if i==j:\n",
    "                continue\n",
    "            simMeas = metric(data[i], data[j])\n",
    "            user = (simMeas, i, j)\n",
    "            sims.append(user)\n",
    "    sims.sort(reverse=True)\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9366996388217678, 60, 67),\n",
       " (0.9281184407526155, 36, 67),\n",
       " (0.9211802501682792, 9, 60),\n",
       " (0.9192813981299488, 9, 67),\n",
       " (0.9107610183340304, 36, 60)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_items(X_train)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(user, joke, k, sims):\n",
    "    simsMat = [sims[i] for i in range(len(sims)) if sims[i][1] == joke or sims[i][2]==joke][:k]\n",
    "    top_jokes = []\n",
    "    for i in range(len(simsMat)):\n",
    "        if simsMat[i][1] != joke:\n",
    "            top_jokes.append(simsMat[i][1])\n",
    "        else:\n",
    "            top_jokes.append(simsMat[i][2])\n",
    "    rates = []\n",
    "    for r in top_jokes:\n",
    "        rate = df[user][r]\n",
    "        if rate != 0:\n",
    "            rates.append(rate)\n",
    "    return np.mean(rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user 3 for joke 4 predicted: 12.905\n",
      "actual rating for joke 4 is: 5.61\n"
     ]
    }
   ],
   "source": [
    "User = 3\n",
    "Joke = 4\n",
    "K = 4\n",
    "msi = most_similar_items(X_train)\n",
    "predict_user = prediction(User, Joke, K, msi)\n",
    "print(\"user {} for joke {} predicted: {}\".format(User, Joke, predict_user))\n",
    "print(\"actual rating for joke {} is: {}\".format(Joke, df[User][Joke]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate [10.56, 12.165, 14.719999999999999, 12.905, 12.905]\n",
      "distance [4.95, 6.554999999999999, 9.11, 7.294999999999999, 7.294999999999999]\n"
     ]
    }
   ],
   "source": [
    "estimate = []\n",
    "for i in range(1,100):\n",
    "    estimate.append(prediction(User, Joke, i, msi))\n",
    "\n",
    "distance = []\n",
    "for j in range(len(estimate)):\n",
    "    distance.append(abs(estimate[j] - df[User][Joke]))\n",
    "print(\"estimate\",estimate[:5])\n",
    "print(\"distance\",distance[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(distance)\n",
    "plt.xlabel(\"k value\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Cross validation accuracies accros k values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user 4 for joke 7 predicted: 10.731549295774649\n",
      "actual rating for joke 7 is: 2.84\n"
     ]
    }
   ],
   "source": [
    "User = 4\n",
    "Joke = 7\n",
    "b_k= distance.index(min(distance)) + 1\n",
    "predict_User = prediction(User, Joke,b_k, msi)\n",
    "print(\"user {} for joke {} predicted: {}\".format(User, Joke, predict_User))\n",
    "print(\"actual rating for joke {} is: {}\".format(Joke, df[User][Joke]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user 5 for joke 15 predicted: 10.731549295774649\n",
      "actual rating for joke 15 is: 8.72\n"
     ]
    }
   ],
   "source": [
    "User = 5\n",
    "Joke = 15\n",
    "print(\"user {} for joke {} predicted: {}\".format(User, Joke, predict_User))\n",
    "print(\"actual rating for joke {} is: {}\".format(Joke, df[User][Joke]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('14023': virtualenv)",
   "language": "python",
   "name": "python37364bit14023virtualenv43d760947b1c41cea019d510c4f98b52"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
